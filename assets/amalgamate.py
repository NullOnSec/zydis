#!/usr/bin/env python3

from pathlib import Path
from typing import List, Set, Tuple, Optional
from shutil import rmtree

import os
import re

ZYDIS_ROOT = Path(__file__).resolve().parent.parent
PUBLIC_INCLUDE_PATHS = [
    ZYDIS_ROOT / 'include',
    ZYDIS_ROOT / 'dependencies' / 'zycore' / 'include',
]
INTERNAL_INCLUDE_PATHS = [ZYDIS_ROOT / 'src']
INCLUDE_REGEXP = re.compile(r'^#\s*include\s*<((?:Zy|Generated).*)>\s*$')
OUTPUT_DIR = ZYDIS_ROOT / 'amalgamated-dist'
FILE_HEADER = ['// DO NOT EDIT. This file is auto-generated by `amalgamate.py`.', '']


def find_files(
    pattern: re.Pattern,
    root_dir: Path,
):
    root_dir = root_dir.resolve()
    paths = []
    for root, dirs, files in os.walk(root_dir):
        paths.extend([Path(root) / name for name in files if pattern.match(name)])

    return sorted(paths)


def find_include_path(
    include: str,
    search_paths: List[Path],
) -> Path:
    for search_path in search_paths:
        path = search_path / include
        if path.exists():
            return path.absolute()
    else:
        raise FileNotFoundError(f'can\'t find header: {include}')


def merge_headers(
    *,
    header: str,
    search_paths: List[Path],
    covered_headers: Set[Path],
    stack: List[str],
) -> List[str]:
    # Locate and load header contents.
    path = find_include_path(header, search_paths)
    with path.open() as f:
        lines = [x.rstrip() for x in f]

    if header in covered_headers:
        return []

    print(f'Processing header "{header}"')
    covered_headers.add(header)

    # Print the header we emit next & the include stack (if non-root).
    include_stack = []
    if stack:
        include_stack = [
            '//',
            '// Include stack:',
            *(f'//   - {x}' for x in stack)
        ]

    filtered = [
        f'',
        f'//',
        f'// Header: {header}',
        *include_stack,
        f'//',
        f'',
    ]

    # Copy over lines and recursively inline all headers.
    for line in lines:
        match = INCLUDE_REGEXP.match(line)
        if not match:
            filtered.append(line)
            continue

        # Recurse into includes.
        filtered += merge_headers(
            header=match.group(1),
            search_paths=search_paths,
            covered_headers=covered_headers,
            stack=stack + [header],
        )

    return filtered


def merge_sources(*, source_dir: Path, covered_headers: Set[Path]):
    output = [
        '#include <Zydis.h>',
        '',
    ]

    for source_file in find_files(re.compile('[\w-]+\.c'), source_dir):
        print(f'Processing source file "{source_file}"')

        # Print some comments to show where the code is from.
        output += [
            f'',
            f'//',
            f'// Source file: {source_file}',
            f'//',
            f'',
        ]

        # Read source file.
        with (source_dir / source_file).open() as f:
            lines = [x.rstrip() for x in f]

        # Walk source file's lines.
        for line in lines:
            # Emit non-includes as-is.
            match = INCLUDE_REGEXP.match(line)
            if not match:
                output.append(line)
                continue
            path = match.group(1)

            if path in covered_headers:
                continue

            if 'Internal' not in path and 'Generated' not in path:
                print(
                    f'WARN: Including header that looks like it is public '
                    f'and should thus already be covered by `Zydis.h` '
                    f'during processing of source files: {path}'
                )

            print(f'Processing internal header "{path}"')
            output += merge_headers(
                header=path,
                search_paths=PUBLIC_INCLUDE_PATHS + INTERNAL_INCLUDE_PATHS,
                covered_headers=covered_headers,
                stack=[],
            )

    return output


def extract_constants(header_contents: List[str]):
    from clang.cindex import Index, CursorKind, TranslationUnit, TokenKind

    tu = Index.create().parse(
        'input.c',
        args=['-x', 'c'],
        unsaved_files=[('input.c', '\n'.join(header_contents))],
        options=TranslationUnit.PARSE_DETAILED_PROCESSING_RECORD,
    )

    defines = {}
    for cursor in tu.cursor.walk_preorder():
        if cursor.kind != CursorKind.MACRO_DEFINITION:
            continue

        name, *tokens = (x.spelling for x in cursor.get_tokens())
        if name.startswith('ZYDIS_') or name.startswith('ZYAN_'):
            parsed = eval_constexpr(' '.join(tokens))
            if parsed is not None:
                defines[name] = parsed

    enums = {}

    def visit_node(node):
        if node.kind == CursorKind.ENUM_DECL:
            enums[node.spelling] = {
                child.spelling: child.enum_value
                for child in node.get_children()
                if child.kind == CursorKind.ENUM_CONSTANT_DECL
            }

        for child in node.get_children():
            visit_node(child)

    visit_node(tu.cursor)

    return enums, defines


def eval_constexpr(expression):
    import clang.cindex

    source = f"enum blah : unsigned long long {{ x = ({expression}) }};"

    tu = clang.cindex.Index.create().parse(
        'temp.cc',
        unsaved_files=[('temp.cc', source)],
    )

    for diag in tu.diagnostics:
        if diag.severity >= clang.cindex.Diagnostic.Error:
            # print(f'unhappy clang: {diag}')
            return None  # Return None if there are any errors

    enum_cursor = next(
        c for c in tu.cursor.walk_preorder()
        if c.kind == clang.cindex.CursorKind.ENUM_CONSTANT_DECL
    )

    return enum_cursor.enum_value


def format_constant(x: int) -> str:
    return f'0x{x:x}' if x > 9999 else f'{x}'


def minify_sources(header_lines: List[str], source_lines: List[str]) -> List[str]:
    enum_values, defines = extract_constants(header_lines + source_lines)

    constants = [
        (k, format_constant(v))
        for k, v in defines.items()
    ] + [
        (k, format_constant(v))
        for enum_name, enum_values in enum_values.items()
        for k, v in enum_values.items()
    ]

    from pprint import pprint
    pprint(constants)

    enum_replacers = [
        re.compile(f'([^A-Za-z0-9_]){k}([^A-Za-z0-9_])')
        for k, v in constants
    ]

    not_min_re = re.compile(r'ZYDIS_NOTMIN\((.*?)\)')
    define_re = re.compile(r'#\s*define')
    enum_re = re.compile(r'enum\s+Zydis')

    out = []
    in_enum = False
    for line in source_lines:
        if define_re.match(line):
            out.append(line)
            continue

        stripped_line = line.strip()
        if stripped_line.startswith('enum') or stripped_line.startswith('typedef enum'):
            in_enum = True
        if stripped_line.startswith('}'):
            in_enum = False

        line = not_min_re.sub(',\\1', line)

        if not in_enum:
            for regex, (const_name, const_val) in zip(enum_replacers, constants):
                if const_name in line:
                    line = regex.sub(f'\\g<1>{const_val}\\g<2>', line)

        out.append(line)

    return out


def main():
    if OUTPUT_DIR.exists():
        print('Output directory exists. Deleting.')
        rmtree(OUTPUT_DIR)

    OUTPUT_DIR.mkdir()

    covered_headers = set()
    header_lines = FILE_HEADER + merge_headers(
        header='Zydis/Zydis.h',
        search_paths=PUBLIC_INCLUDE_PATHS,
        covered_headers=covered_headers,
        stack=[],
    )

    with open(OUTPUT_DIR / 'Zydis.h', 'w') as f:
        f.write('\n'.join(header_lines))

    source_lines = FILE_HEADER + merge_sources(
        source_dir=ZYDIS_ROOT / 'src',
        covered_headers=covered_headers,
    )

    minified_source_lines = minify_sources(header_lines, source_lines)

    with open(OUTPUT_DIR / 'Zydis.c', 'w') as f:
        f.write('\n'.join(minified_source_lines))


if __name__ == '__main__':
    main()
